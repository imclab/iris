* TODO Get something working.
  #+BEGIN_SRC java :tangle working.bsh :shebang #!/usr/bin/env bsh
    addClassPath("lib/stt.jar");
    addClassPath("lib/minim.jar");
    addClassPath("lib/minim-spi.jar");
    addClassPath("lib/jsminim.jar");
    addClassPath("lib/tritonus_share.jar");
    addClassPath("lib/javaFlacEncoder-0.1.jar");
    addClassPath("lib/core.jar");
    
    import com.getflourish.stt.STT;
    import processing.core.PApplet;
    
    new PApplet() {
            public setup() {
                // size(400, 400);
                print("oeunthouethn");
                noLoop();
            }
    
            draw() {
                // background(0);
            }
    
            transcribe(utterance, confidence) {
            }
    
            keyPressed() {
            }
    
            keyReleased() {
            }
        };
    
    stt = new STT(applet);
    
  #+END_SRC

  If we're going to do this without the autorecord and processing
  cruft, we need (I was going to say [[http://code.compartmental.net/tools/minim/][minim]], but it's some kind of
  Processing-specific piece of shit) [[http://www.tritonus.org/][tritonus]].

  On the [[https://github.com/fx-lange/ofxGSTT][C-side]], on the other hand, there's [[http://www.mega-nerd.com/libsndfile/][sndfile]] and [[http://flac.sourceforge.net/][libFlac]]; looks
  like [[http://freedesktop.org/software/pulseaudio/doxygen/simple.html][pulseaudio]]'s the way to go, though, for actually recording.

  What about [[http://www.jsresources.org/examples/audio_playing_recording.html][this shit]] on Java? Or [[http://docs.oracle.com/javase/tutorial/sound/accessing.html][from scratch]]. Write with [[http://javaflacencoder.sourceforge.net/][this]]?
  [[http://www.jsresources.org/examples/audio_playing_recording.html][Examples]] of recording to file.

  Now that we have an =AudioInputStream=, can we avoid serializing it
  before converting to FLAC? =AudioSystem.write= takes an
  =OutputStream=, by the way.

  #+BEGIN_SRC java :tangle mixer.bsh :shebang #!/usr/bin/env bsh
    addClassPath("lib/guava-10.0.1.jar");
    addClassPath("lib/javaFlacEncoder-0.2.3.jar");
    addClassPath("lib/jflac-codec-1.4.0-SNAPSHOT.jar");
    
    import javax.sound.sampled.AudioSystem;
    import javax.sound.sampled.Port;
    import javax.sound.sampled.TargetDataLine;
    import javax.sound.sampled.DataLine;
    import javax.sound.sampled.AudioFormat;
    import javax.sound.sampled.AudioInputStream;
    import javax.sound.sampled.AudioFileFormat;
    import java.util.Timer;
    import java.util.TimerTask;
    import java.io.ByteArrayOutputStream;
    
    import com.google.common.collect.ObjectArrays;
    import javaFlacEncoder.FLACFileOutputStream;
    import javaFlacEncoder.FLAC_FileEncoder;
    import javaFlacEncoder.StreamConfiguration;
    import org.kc7bfi.jflac.sound.spi.FlacEncoding;
    import org.kc7bfi.jflac.sound.spi.FlacFileFormatType;
    import org.kc7bfi.jflac.sound.spi.FlacFormatConversionProvider;
    
    // It's a shame we have to specify this: command-line param?
    INPUT_INDEX = 1;
    FORMAT = new AudioFormat(8000, 16, 1, true, false);
    
    mixerInfo = AudioSystem.getMixerInfo()[INPUT_INDEX];
    target = AudioSystem.getTargetDataLine(FORMAT, mixerInfo);
    target.open(FORMAT);
    target.start();
    
    timer = new Timer();
    task = new TimerTask() {
            public void run() {
                // Otherwise, our WAV is truncated.
                target.flush();
                target.stop();
                target.close();
                // Otherwise, the program never terminates.
                timer.cancel();
            }
        };
    timer.schedule(task, 10000);
    
    inputStream = new AudioInputStream(target);
    
    wave = new File("harro.wav");
    flac = new File("harro.flac");
    
    AudioSystem.write(inputStream,
                      AudioFileFormat.Type.WAVE,
                      wave);
    
    encoder = new FLAC_FileEncoder();
    encoder.setStreamConfig
        (new StreamConfiguration(1,
                                 StreamConfiguration.DEFAULT_MIN_BLOCK_SIZE,
                                 StreamConfiguration.DEFAULT_MAX_BLOCK_SIZE,
                                 8000,
                                 16));
    encoder.encode(wave, flac);
    
  #+END_SRC

  This works, by the way (based on [[http://getstreaming.wordpress.com/tag/speech-to-text/][this]]):

  #+BEGIN_SRC sh
    curl -H "Content-Type: audio/x-flac; rate=16000" -F Content=@harro.flac -k 'https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&lang=en-US'
    # {"status":0,"id":"fa71c13664c1b6804bd7f2ef84a2a4e0-1","hypotheses":[{"utterance":"test","confidence":0.95221627}]}
  #+END_SRC

  Having been converted with this:

  #+BEGIN_SRC sh
    sox harro.wav -2 -r 16000 harro.flac
  #+END_SRC

  [[http://www.developer.com/java/other/article.php/2105421/Java-Sound-Capturing-Microphone-Data-into-an-Audio-File.htm][By the way]]:

  #+BEGIN_QUOTE
: In addition to its other features, the AudioSystem.write method knows
: how to detect that the stop method has been invoked on the
: TargetDataLine object (see Listing 7) and to close the output file
: when that happens.  
  #+END_QUOTE

  It would be pretty cool to detect starts and stops in the sound
  stream and not have to rely on e.g. timers and button-events; this
  can be a later optimization, though (also, take a look at the source
  for Florian Schulz' [[http://stt.getflourish.com/][Processing-plugin]]).

  We should have an alternative, by the way, that pulls in the first
  compatible =TargetDataLine= (and only resorts to a specific index
  when necessary); in other words, it should be possible to specify
  the default source and call it a day (though this didn't work for us
  using PulseAudio).

  Florian Schulz even did things like the "analysis of the
  environmental volume after initialization" (which appears to take
  the max volume over a two-second interval; discarding the average,
  AFAICT):

  #+BEGIN_SRC java
    private void analyzeEnv() {
        if (!analyzing) {
            timer2 = new Timer(2000);
            timer2.start();
            analyzing = true;
            volumes = new ArrayList<Float>();
        }
        if (timer2 != null) {
            if (!timer2.isFinished()) {
                float volume = in.mix.level() * 1000;
                volumes.add(volume);
            } else {
                float avg = 0.0f;
                float max = 0.0f;
                for (int i = 0; i < volumes.size(); i++) {
                    avg += volumes.get(i);
                    if (volumes.get(i) > max) max = volumes.get(i);
                }
                avg /= volumes.size();
                threshold = (float) Math.ceil(max);
                System.out.println(getTime() + " Volume threshold automatically set to " + threshold);
                analyzing = false;
            }   
        }   
    }
  #+END_SRC

  Look at the encoding from Wave to FLAC, by the way:

  #+BEGIN_SRC java
    private void onSpeechFinish()
    {
        status = "Transcribing";
        fired = false;
        recorder.endRecord();
        recorder.save();
        recording = false;
            
        dispatchTranscriptionEvent(transcriptionThread.getUtterance(), transcriptionThread.getConfidence(), STT.TRANSCRIBING);
            
        // Encode the wav to flac
        String flac = path + fileName + fileCount + ".flac";
        encoder.encode(new File(path + fileName + fileCount + ".wav"), new File(flac));
        boolean exists = (new File(flac)).exists();
        while(exists == false)
            {   
                exists = (new File(flac)).exists();     
            }
        
        if (exists) {
            this.transcribe(flac);
        } else {
            System.err.println("Could not transcribe. File was not encoded in time.");
        }
            
        // new file for new speech
        if (log) fileCount++;
    }
    
  #+END_SRC

  Here's the =handleAuto= loop: where it analyses the environment,
  sets up the threshould, and dispatches:

  #+BEGIN_SRC java
    private void handleAuto () {
        if (analyzing) analyzeEnv();
        updateVolume(); 
        if (volume > threshold) {
            // start recording when someone says something louder than threshold
            onSpeech();
        } else {
            // the magic begins. save it. transcribe it.
            if (timer.isFinished() && volume < threshold && recorder.isRecording() && recording) {
                onSpeechFinish();
            } else if (timer.isFinished() && volume < threshold && !recorder.isRecording()){
                startListening();
            }
        }
    }
    
  #+END_SRC

  No FFT, though; [[https://github.com/taf2/audiosplit][audiosplit]], on the other hand, is doing some kind of
  root-mean-square analysis. =handleAuto= is called everytime there's
  a draw-event, by the way:

  #+BEGIN_SRC java
    public void draw() {    
        if (auto) handleAuto();
        // handles active threads and callbacks
        for (int i = 0; i < threads.size(); i++) {
            transcriptionThread = threads.get(i); 
            transcriptionThread.debug = debug;
            if (transcriptionThread.isAvailable()) {
                if (transcriptionEvent != null) {
                    try {
                        transcriptionEvent.invoke(p, new Object[] { transcriptionThread.getUtterance(), transcriptionThread.getConfidence()});
                    } catch (IllegalArgumentException e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                    } catch (IllegalAccessException e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                    } catch (InvocationTargetException e) {
    
                    }
                } else if (transcriptionEvent2 != null) {
                    dispatchTranscriptionEvent(transcriptionThread.getUtterance(), transcriptionThread.getConfidence(), transcriptionThread.getStatus());
                }
                threads.remove(i);
            }
    
            if (debug && !status.equals(lastStatus)) {
                System.out.println(getTime() + " " + status);
                lastStatus = status;
            }
        }
    }
    
  #+END_SRC

  Call-back for the reduction-event is: =(lambda (hypothesis
  confidence) ...)=; register a series of parsers which either bite or
  pass on. Initially, though, just a parser. Or: one parser; multiple
  dispatchers? Yes.

  =jflac= is out of the question, since the encoder apparently [[https://github.com/hoenigmann/sicp.git][hasn't
  been implemented]]; the =javaFlacEncoder= has [[https://github.com/hoenigmann/sicp.git][FLACEncoder]] and
  [[https://github.com/hoenigmann/sicp.git][FLAC_FileEncoder]] (which Schultz used). The latter requires you to
  serialize wav, convert to FLAC, and send; the former is more complex
  to use, but can encode without serialization.

  We'll serialize to wav first; optimize later?

  HTTP-clients: [[http://hc.apache.org/][Apache commons]]; [[https://github.com/dakrone/clj-http][Clojure wrapper]]. [[http://hc.apache.org/httpcomponents-client-ga/tutorial/html/fundamentals.html#d4e199][Chunked encoding]] with
  name; [[http://hc.apache.org/httpcomponents-client-ga/httpclient/examples/org/apache/http/examples/client/ClientChunkEncodedPost.java][chunked encoding]] with POST. [[http://www.java-tips.org/other-api-tips/httpclient/how-to-use-multipart-post-method-for-uploading.html][Multi-part POST]]; where
  [[http://stackoverflow.com/questions/1067655/how-to-upload-a-file-using-java-httpclient-library-working-with-php-strange-pr][rebuketh]]. [[http://evgeny-goldin.com/blog/uploading-files-multipart-post-apache/][Writeup]] from Evgeny Goldin; referencing [[http://radomirml.com/2009/02/13/file-upload-with-httpcomponents-successor-of-commons-httpclient][this]] (which shows,
  by the way, how to upload from stream).

  ([[http://create.spinvox.com/][SpinVox]] as an alternative to Google, by the way.)

  Florian uses =file= as the parameter; the curl example uses
  =Content=: they both work.

  #+BEGIN_SRC java
    HttpClient client = new DefaultHttpClient();
    client.getParams().setParameter(CoreProtocolPNames.PROTOCOL_VERSION, HttpVersion.HTTP_1_1);
     
    HttpPost        post   = new HttpPost( url );
    MultipartEntity entity = new MultipartEntity( HttpMultipartMode.BROWSER_COMPATIBLE );
     
    // For File parameters
    entity.addPart( paramName, new FileBody((( File ) paramValue ), "application/zip" ));
     
    // For usual String parameters
    entity.addPart( paramName, new StringBody( paramValue.toString(), "text/plain",
                                               Charset.forName( "UTF-8" )));
     
    post.setEntity( entity );
     
    // Here we go!
    String response = EntityUtils.toString( client.execute( post ).getEntity(), "UTF-8" );
     
    client.getConnectionManager().shutdown();
  #+END_SRC

  #+BEGIN_SRC java :tangle post-to-google.bsh :shebang #!/usr/bin/env bsh
    addClassPath("lib/httpcore-4.2-alpha2.jar");
    addClassPath("lib/httpclient-4.2-alpha1.jar");
    addClassPath("lib/httpmime-4.2-alpha1.jar");
    addClassPath("lib/commons-logging-1.1.1.jar");
    addClassPath("lib/gson-2.0.jar");
    
    import java.io.File;
    
    import org.apache.http.HttpVersion;
    import org.apache.http.client.methods.HttpPost;
    import org.apache.http.entity.mime.HttpMultipartMode;
    import org.apache.http.entity.mime.MultipartEntity;
    import org.apache.http.entity.mime.content.FileBody;
    import org.apache.http.entity.mime.content.StringBody;
    import org.apache.http.impl.client.DefaultHttpClient;
    import org.apache.http.params.CoreProtocolPNames;
    import org.apache.http.util.EntityUtils;
    
    client = new DefaultHttpClient();
    client.getParams().setParameter(CoreProtocolPNames.PROTOCOL_VERSION,
                                    HttpVersion.HTTP_1_1);
    post = new HttpPost("https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&lang=en-US");
    post.addHeader("Content-type", "audio/x-flac; rate=8000");
    entity = new MultipartEntity(HttpMultipartMode.BROWSER_COMPATIBLE);
    entity.addPart("Content", new FileBody(new File("harro.flac"), "audio/x-flac"));
    post.setEntity(entity);
    response = EntityUtils.toString(client.execute(post).getEntity(), "UTF-8");
    print(response);
    client.getConnectionManager().shutdown();
  #+END_SRC

  With Gson, I think we've reached the limit of beanshell; can't
  seem to define adequate classes.

  #+BEGIN_SRC java :tangle parse-json.bsh :shebang #!/usr/bin/env bsh
    addClassPath("lib/gson-2.0.jar");
    
    import com.google.gson.Gson;
    import com.google.gson.reflect.TypeToken;
    
    response = "{\"status\":0,\"id\":\"85afc1835bc8583519599abebfd99d81-1\",\"hypotheses\":[{\"utterance\":\"toyota\",\"confidence\":0.95395637}]}";
    
    public class Response {
        int status;
        String id;
        Hypothesis[] hypotheses;
    
        public class Hypothesis {
            String utterance;
            float confidence;
        }
    }
    
    new Gson().fromJson(response, Response.class);
    
  #+END_SRC

  Rudy mentioned some stuff over farmer's that I didn't capture;
  something about [[http://en.wikipedia.org/wiki/Root_mean_square][mean square]] (as opposed to root mean square) for
  establishing a threshold. More sophisticated models do a band-pass
  filter for (possibly gender-specific) frequencies. Have to ask him
  for clarity. The model of take-the-max over $n$ milliseconds (Rudy
  mentioned that 10-20 is legit, btw) is terrible when dealing with
  e.g. spikes.

  #+BEGIN_SRC clojure :tangle record.clj :shebang #!/usr/bin/env clj
    (use 'add-classpath.core)
    
    (add-classpath "lib/javaFlacEncoder-0.2.3.jar")
    (add-classpath "lib/debug-1.0.0-SNAPSHOT.jar")
    (add-classpath "lib/lambda-1.0.1-SNAPSHOT.jar")
    
    (use 'debug.core)
    (use 'lambda.core)
    
    (import '(javax.sound.sampled
              AudioFormat
              AudioSystem
              AudioInputStream
              AudioFileFormat
              AudioFileFormat$Type))
    (import '(java.util
              Timer
              TimerTask))
    (import '(java.io
              File))
    (import '(javaFlacEncoder
              FLAC_FileEncoder
              StreamConfiguration))
    
    (def ^:dynamic *input-index* 
      "Default index of the recording device; NB: this is a hack."
      1)
    
    (def ^:dynamic *sample-rate* 8000)
    
    (def ^:dynamic *sample-size* 16)
    
    (def ^:dynamic *channels* 1)
    
    (def ^:dynamic *signed* true)
    
    (def ^:dynamic *big-endian* false)
    
    (def ^:dynamic *format*
      (new AudioFormat
           *sample-rate*
           *sample-size*
           *channels*
           *signed*
           *big-endian*))
    
    (def ^:dynamic *prefix* "iris")
    
    (def create-temporary-file
      (λ [suffix] (File/createTempFile *prefix* suffix)))
    
    (def create-temporary-wave
      (λ [] (create-temporary-file ".wav")))
    
    (def create-temporary-flac
      (λ [] (create-temporary-file ".flac")))
    
    (let [mixer-info (get (AudioSystem/getMixerInfo) *input-index*)
          target (AudioSystem/getTargetDataLine *format* mixer-info)]
      ;; `with-open'?
      (.open target *format*)
      (.start target)
      (let [timer (new Timer)
            task (proxy [TimerTask] []
                   (run []
                     (.flush target)
                     (.stop target)
                     (.close target)
                     (.cancel timer)))]
        (.schedule timer task 5000))
      (let [input-stream (new AudioInputStream target)]
        (let [wave (create-temporary-wave)
              flac (create-temporary-flac)]
          (AudioSystem/write input-stream
                             AudioFileFormat$Type/WAVE
                             wave)
          (let [encoder (new FLAC_FileEncoder)]
            (.setStreamConfig encoder
                              (new StreamConfiguration
                                   *channels*
                                   StreamConfiguration/DEFAULT_MIN_BLOCK_SIZE
                                   StreamConfiguration/DEFAULT_MAX_BLOCK_SIZE
                                   *sample-rate*
                                   *sample-size*))
            (.encode encoder wave flac)
            (debug (.getAbsolutePath flac))))))
    
  #+END_SRC

  #+BEGIN_SRC clojure :tangle post.clj :shebang #!/usr/bin/env clj
    (use 'add-classpath.core)
    
    (add-classpath "lib/debug-1.0.0-SNAPSHOT.jar")
    (add-classpath "lib/clj-http-0.2.6-SNAPSHOT-standalone.jar")
    (add-classpath "lib/data.json-0.1.3-SNAPSHOT.jar")
    (add-classpath "lib/lambda-1.0.1-SNAPSHOT.jar")
    (add-classpath "lib/cadr-1.0.0-SNAPSHOT-standalone.jar")
    
    (use 'clojure.java.io)
    (use 'debug.core)
    (use 'clj-http.client)
    (use 'slingshot.slingshot)
    (use 'clojure.data.json)
    (use 'lambda.core)
    (use 'cadr.core)
    
    (import 'java.util.Random)
    
    (let [random (new Random)]
      (def random-element
        (λ [list]
           (nth list (.nextInt random (count list))))))
    
    (def sort-hypotheses
      (λ [hypotheses]
         (sort-by (λ [hypothesis]
                     (let [{utterance :utterance confidence :confidence}
                           hypothesis]
                       confidence))
                  >
                  hypotheses)))
    
    (def parse-response
      (λ [response]
         (let [{status :status
                id :id
                hypotheses :hypotheses}
               (read-json response)
               {utterance :utterance
                confidence :confidence}
               (car (sort-hypotheses hypotheses))]
           {:utterance utterance
            :confidence confidence})))
    
    (def post-to-google
      (λ [flac]
         (:body
          (post "https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&lang=en-US"
                {:multipart [["Content" (file flac)]]
                 :headers {"Content-type" "audio/x-flac; rate=8000"}}))))
    
    (debug (parse-response (post-to-google "harro.flac")))
    
  #+END_SRC

  #+BEGIN_SRC clojure :tangle record-and-post.clj :shebang #!/usr/bin/env clj
    (use 'add-classpath.core)
    
    (add-classpath "lib/*")
    
    (use 'cadr.core)
    (use '[clj-http.client :only (post)])
    (use 'clojure.data.json)
    (use 'clojure.java.io)
    (use 'debug.core)
    (use 'lambda.core)
    (use 'slingshot.slingshot)
    
    (import '(java.io
              File))
    (import '(java.util
              Timer
              TimerTask
              Random))
    (import '(javax.sound.sampled
              AudioFormat
              AudioSystem
              AudioInputStream
              AudioFileFormat
              AudioFileFormat$Type))
    
    (import '(javaFlacEncoder
              FLAC_FileEncoder
              StreamConfiguration))
    
    (def ^:dynamic *input-index* 
      "Default index of the recording device; NB: this is a hack."
      1)
    
    (def ^:dynamic *sample-rate* 8000)
    
    (def ^:dynamic *sample-size* 16)
    
    (def ^:dynamic *channels* 1)
    
    (def ^:dynamic *signed* true)
    
    (def ^:dynamic *big-endian* false)
    
    (def ^:dynamic *format*
      (new AudioFormat
           *sample-rate*
           *sample-size*
           *channels*
           *signed*
           *big-endian*))
    
    (def ^:dynamic *prefix* "iris")
    
    (def create-temporary-file
      (λ [suffix] (File/createTempFile *prefix* suffix)))
    
    (def create-temporary-wave
      (λ [] (create-temporary-file ".wav")))
    
    (def create-temporary-flac
      (λ [] (create-temporary-file ".flac")))
    
    (let [random (new Random)]
      (def random-element
        (λ [list]
           (nth list (.nextInt random (count list))))))
    
    (def sort-hypotheses
      (λ [hypotheses]
         (sort-by (λ [hypothesis]
                     (let [{utterance :utterance confidence :confidence}
                           hypothesis]
                       confidence))
                  >
                  hypotheses)))
    
    (def parse-response
      (λ [response]
         (let [{status :status
                id :id
                hypotheses :hypotheses}
               (read-json response)
               {utterance :utterance
                confidence :confidence}
               (car (sort-hypotheses hypotheses))]
           {:utterance utterance
            :confidence confidence})))
    
    (def ^:dynamic *google-url*
      "https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&lang=en-US")
    
    (def post-to-google
      (λ [flac]
         (:body
          (post *google-url*
                {:multipart [["Content" flac]]
                 :headers {"Content-type"
                           (format "audio/x-flac; rate=%s" *sample-rate*)}}))))
    
    (let [mixer-info (get (AudioSystem/getMixerInfo) *input-index*)
          target (AudioSystem/getTargetDataLine *format* mixer-info)]
      ;; `with-open'?
      (.open target *format*)
      ;; (read-line)
      (println "Start recording.")
      (.start target)
      (let [timer (new Timer)
            task (proxy [TimerTask] []
                   (run []
                     (.flush target)
                     (.stop target)
                     (println "Stop recording.")
                     (.close target)
                     (.cancel timer)))]
        (.schedule timer task 2000))
      (let [input-stream (new AudioInputStream target)]
        (let [wave (create-temporary-wave)
              flac (create-temporary-flac)]
          (AudioSystem/write input-stream
                             AudioFileFormat$Type/WAVE
                             wave)
          (let [encoder (new FLAC_FileEncoder)]
            (.setStreamConfig encoder
                              (new StreamConfiguration
                                   *channels*
                                   StreamConfiguration/DEFAULT_MIN_BLOCK_SIZE
                                   StreamConfiguration/DEFAULT_MAX_BLOCK_SIZE
                                   *sample-rate*
                                   *sample-size*))
            (.encode encoder wave flac)
            (debug (parse-response (post-to-google flac)))))))
  #+END_SRC

  We can just do something like this, by the way, without worrying
  about lat/long:

  #+BEGIN_SRC clojure
    (fun/fetch :places :q "Starbucks,Santa Monica")
  #+END_SRC
* TODO Geocoding, reverse geocoding
  Check out this [[http://code.google.com/apis/maps/documentation/geocoding/][Google library]]. Also [[http://www.maxmind.com/app/geolitecity][GeoLite City]] for getting city
  from IP (a hack, to be sure). [[http://snipplr.com/view/7985/googleloaderclientlocation-to-get-a-persons-latlong-using-their-ip-address/][google.loader.ClientLocation]] (for
  browers, though). [[http://www.caida.org/tools/utilities/netgeo/][NetGeo]] used to work. [[http://www.geobytes.com/IpLocator.htm][GeoBytes]]. [[http://code.google.com/apis/latitude/v1/using_rest.html][Google Latitude]].

  http://code.google.com/apis/accounts/docs/OAuth2InstalledApp.html

  Even using the [[http://code.google.com/p/google-api-java-client/wiki/APIs#Google_Latitude_API][Latitude Java sample]], though, it was a bust.

  [[http://www.hostip.info/use.html][Community-driven]]:

  #+BEGIN_EXAMPLE
    $ curl http://api.hostip.info/get_html.php
    Country: UNITED STATES (US)
    City: Los Angeles, CA
    IP: 76.79.81.162    
  #+END_EXAMPLE

  Also:

  #+BEGIN_EXAMPLE
    $ curl 'http://www.geobytes.com/IpLocator.htm?GetLocation&template=php3.txt&IpAddress=76.79.81.162'
    <html>
    <head>
    
    <meta name="known" content="true">
    <meta name="locationcode" content="USCALANG">
    <meta name="fips104" content="US">
    <meta name="iso2" content="US">
    <meta name="iso3" content="USA">
    <meta name="ison" content="840">
    <meta name="internet" content="US">
    <meta name="countryid" content="254">
    <meta name="country" content="United States">
    <meta name="regionid" content="126">
    <meta name="region" content="California">
    <meta name="regioncode" content="CA">
    <meta name="adm1code" content="    ">
    <meta name="cityid" content="7275">
    <meta name="city" content="Los Angeles">
    <meta name="latitude" content="34.0452">
    <meta name="longitude" content="-118.2840">
    <meta name="timezone" content="-08:00">
    <meta name="certainty" content="97">
    <meta name="mapbytesremaining" content="Free">
    
    <title>PHP2 Template</title>
    </head>
    <body></body>
    </html>
    
  #+END_EXAMPLE

  We should be able to do a city -> lat/long without all the OAuth
  shit via [[http://code.google.com/apis/maps/documentation/geocoding/index.html][Google]] (just cities, though, not establishments; see
  [[places]] below):

  #+BEGIN_EXAMPLE
    $ curl 'http://maps.googleapis.com/maps/api/geocode/xml?address=factual+inc,los+angeles+ca&sensor=false'
    <?xml version="1.0" encoding="UTF-8"?>
    <GeocodeResponse>
     <status>OK</status>
     <result>
      <type>locality</type>
      <type>political</type>
      <formatted_address>Los Angeles, CA, USA</formatted_address>
      <address_component>
       <long_name>Los Angeles</long_name>
       <short_name>Los Angeles</short_name>
       <type>locality</type>
       <type>political</type>
      </address_component>
      <address_component>
       <long_name>Los Angeles</long_name>
       <short_name>Los Angeles</short_name>
       <type>administrative_area_level_2</type>
       <type>political</type>
      </address_component>
      <address_component>
       <long_name>California</long_name>
       <short_name>CA</short_name>
       <type>administrative_area_level_1</type>
       <type>political</type>
      </address_component>
      <address_component>
       <long_name>United States</long_name>
       <short_name>US</short_name>
       <type>country</type>
       <type>political</type>
      </address_component>
      <geometry>
       <location>
        <lat>34.0522342</lat>
        <lng>-118.2436849</lng>
       </location>
       <location_type>APPROXIMATE</location_type>
       <viewport>
        <southwest>
         <lat>33.7558884</lat>
         <lng>-118.7559225</lng>
        </southwest>
        <northeast>
         <lat>34.3475477</lat>
         <lng>-117.7314473</lng>
        </northeast>
       </viewport>
       <bounds>
        <southwest>
         <lat>33.7036918</lat>
         <lng>-118.6681760</lng>
        </southwest>
        <northeast>
         <lat>34.3373060</lat>
         <lng>-118.1552890</lng>
        </northeast>
       </bounds>
      </geometry>
     </result>
    </GeocodeResponse>    
  #+END_EXAMPLE

# <<places>>
  This [[http://code.google.com/apis/maps/documentation/places/][Google places]] query doesn't work for me:

  #+BEGIN_EXAMPLE
    $ curl 'https://maps.googleapis.com/maps/api/place/search/json?location=-33.8670522,151.1957362&radius=500&types=food&name=harbour&sensor=true&key=<key>'
    {
       "html_attributions" : [],
       "results" : [],
       "status" : "REQUEST_DENIED"
    }    
  #+END_EXAMPLE

  (Had to enable it under the Google API console.)

  #+BEGIN_SRC sh
    curl 'http://api.ipinfodb.com/v3/ip-city/?key=<api-key>'
  #+END_SRC

* TODO Grammar
  We could go [[http://nlp.stanford.edu/software/lex-parser.shtml][Stanford]] on this; but why not start with regular
  expressions? Something to the effect of: "find $x$ near $y$;" where
  $y$ gets thrown into the Factual query:
  #+BEGIN_SRC clojure
    (fun/fetch :places :q "Starbucks,Santa Monica")
  #+END_SRC
  (we could special-case e.g. "me" and locate the user; but that's
  extra credit) and where $x$ is a name or one of the [[http://developer.factual.com/display/docs/Places+API+-+Categories][Factual
  categories]]?

  Can we use pattern matching instead of regular expressions?

  #+BEGIN_SRC clojure :tangle match.clj :shebang #!/usr/bin/env clj
    (use 'add-classpath.core)
    
    (add-classpath "lib/*")
    
    (use '[clojure.core.match :only (match)])
    (use 'debug.core)
    (use '[clojure.string :only (split)])
    (use 'funnyplaces.api)
    
    (source "v3-key-secret.clj")
    
    #_(debug
       (match ['("find" "hair" "removal" "in" "los" "angeles")]
              [(["find" & rest] :seq)]
              (match (partition-by #(= "in" %) rest)
                     [([what in where] :seq)] what)))
    
    (let [query "find hair removal in los angeles"]
      (match (split query #"\\b")
             [(["find" & rest] :seq)]
             (match (partition-by #(= "in" %) rest) 
                    [([what in where] :seq)] what))
      (debug (re-matches #"find (.+) in (.+)" query)))
  #+END_SRC

  #+BEGIN_SRC clojure :tangle factual.clj :shebang #!/usr/bin/env clj
    (use 'add-classpath.core)
    
    (add-classpath "lib/*")
    
    (use 'funnyplaces.api)
    (use 'debug.core)
    
    (load-file "key-secret.clj")
    
    (factual! *key* *secret*)
    
    ;;; We've remove URL encoding from these examples for clarity, but
    ;;; remember to URL encode the entirety of your JSON string before
    ;;; calling.
    (let [query "find hair removal in los angeles"]
      (debug #_(fetch :places :limit 1 :filters {"locality" "los angeles"})
             #_(resolve {"name" "ino", "latitude" 40.73, "longitude" -74.01})
             (let [[query what where] (re-matches #"find (.+) in (.+)" query)]
               (debug what where (format "%s,%s" what where))
               (fetch :places :q (format "%s,%s" what where)))))
    
  #+END_SRC
* TODO Speech-to-text
  #+BEGIN_SRC sh
    curl -A Mozilla "http://translate.google.com/translate_tts?q=i'm+relatively+indifferent+to+techcrunch"
    mplayer "http://translate.google.com/translate_tts?ie=UTF-8&tl=de&q=einst+ging+ich+zum+raggies"
  #+END_SRC

  [[http://espeak.sourceforge.net/][See also.]]

  #+BEGIN_SRC clojure :tangle synthesize.clj :shebang #!/usr/bin/env clj
    (use 'add-classpath.core)
    (add-classpath "lib/*")
    
    (use 'lambda.core)
    (use 'debug.core)
    (use '[clj-http.client :only (get)])
    (use 'clojure.java.io)
    
    (import '(java.io File
                      FileOutputStream))
    (import '(javazoom.jl.player Player))
    
    (def ^:dynamic *prefix* "iris")
        
    (def create-temporary-file
      (λ [suffix] (File/createTempFile *prefix* suffix)))
        
    (def create-temporary-mp3
      (λ [] (create-temporary-file ".mp3")))
    
    (debug (let [mp3 (:body (get "http://translate.google.com/translate_tts"
                                 {:query-params {"ie" "UTF-8"
                                                 "tl" "de"
                                                 "q" "einst ging ich zum raggies haus"
                                                 }
                                  :as :byte-array}))
                 file (create-temporary-mp3)]
             (with-open [file (FileOutputStream. file)]
               (.write file mp3))
             (with-open [player (new Player (input-stream file))]
               (.play player))))
    
  #+END_SRC

  #+BEGIN_SRC clojure :tangle play.clj :shebang #!/usr/bin/env clj
    (use 'clojure.java.io)
    (use 'add-classpath.core)
    (add-classpath "lib/*")
    
    (import '(javazoom.jl.player Player))
    
    (let [mp3 (input-stream "play.mp3")
          player (new Player mp3)]
      (.play player)
      (.close player))
    
  #+END_SRC

  #+BEGIN_SRC clojure :tangle parse-and-play.clj :shebang #!/usr/bin/env clj
    (use 'add-classpath.core)
    (add-classpath "lib/*")
    
    (use 'clojure.data.json)
    (use 'lambda.core)
    (use 'funnyplaces.api)
    (use 'debug.core)
    (use 'clj-http.client)
    (use 'clojure.java.io)
    (use 'cadr.core)
    
    (import '(java.util Random
                        Timer
                        TimerTask))
    (import '(java.io File
                      FileOutputStream))
    (import '(javax.sound.sampled AudioFormat
                                  AudioSystem
                                  AudioInputStream
                                  AudioFileFormat
                                  AudioFileFormat$Type))
    
    (import '(javazoom.jl.player Player))
    
    (import '(javaFlacEncoder FLAC_FileEncoder
                              StreamConfiguration))
    
    (load-file "key-secret.clj")
    
    (factual! *key* *secret*)
    
    (let [random (new Random (System/currentTimeMillis))]
      (def random-element
        (λ [list]
           (nth list (.nextInt random (count list))))))
    
    (def ^:dynamic *prefix* "iris")
             
    (def create-temporary-file
      (λ [suffix] (File/createTempFile *prefix* suffix)))
        
    (def create-temporary-mp3
      (λ [] (create-temporary-file ".mp3")))
    
    (def create-temporary-wave
      (λ [] (create-temporary-file ".wav")))
    
    (def create-temporary-flac
      (λ [] (create-temporary-file ".flac")))
    
    (def default-parser
      (λ [query]
         (let [results (fetch :places
                              :q query
                              :include_count true)
               quotable (format "\"%s\"" query)]
           {:results results
            :quotable quotable})))
    
    (def locality-parser
      (λ [query]
         (let [[query what where]
               (re-matches #"find (.+) in (.+)" query)]
           (if (and what where)
             (let [results (fetch :places
                                  :q what
                                  :filters {"locality" where}
                                  :include_count true)
                   quotable (format "\"%s\" in %s" what where)]
               {:results results
                :quotable quotable})
             false))))
    
    (def parsers (list locality-parser
                       default-parser))
    
    (def parse-query
      (λ [query]
         (loop [parsers parsers]
           (if (empty? parsers)
             {:results []
              :quotable (format "\"%s\"" query)}
             (let [parser (car parsers)
                   result (parser query)]
               (or result (recur (cdr parsers))))))))
    
    (def consider
      (λ [query]
         (println (format "I understood, \"%s.\"" query))
         (let [{results :results
                quotable :quotable}
               (parse-query query),
               {total :total_row_count
                included :included_rows}
               (:response (meta results))]
           (cond (empty? results)
                 (format "I couldn't find any places for %s." quotable)
                 (= 1 total)
                 (format "The only place for %s appears to be %s."
                         quotable
                         (:name (car results)))
                 :else
                 (format "Of the %s or so places for %s, you might like %s."
                         total
                         quotable
                         (:name (random-element results)))))))
    
    (def answer
      (λ [response]
         (println response)
         (let [mp3 (:body (clj-http.client/get "http://translate.google.com/translate_tts"
                               {:query-params {"ie" "UTF-8"
                                               "tl" "en"
                                               "q" response
                                               }
                                :as :byte-array}))
               file (create-temporary-mp3)]
           (with-open [file (FileOutputStream. file)]
             (.write file mp3))
           (with-open [player (new Player (input-stream file))]
             (.play player)))))
    
    (def ^:dynamic *input-index* 
      "Default index of the recording device; NB: this is a hack."
      1)
    
    (def ^:dynamic *sample-rate* 8000)
    
    (def ^:dynamic *sample-size* 16)
    
    (def ^:dynamic *channels* 1)
    
    (def ^:dynamic *signed* true)
    
    (def ^:dynamic *big-endian* false)
    
    (def ^:dynamic *format*
      (new AudioFormat
           *sample-rate*
           *sample-size*
           *channels*
           *signed*
           *big-endian*))
    
    (def sort-hypotheses
      (λ [hypotheses]
         (sort-by (λ [hypothesis]
                     (let [{utterance :utterance confidence :confidence}
                           hypothesis]
                       confidence))
                  >
                  hypotheses)))
    
    (def parse-response
      (λ [response]
         (let [{status :status
                id :id
                hypotheses :hypotheses}
               (read-json response)
               {utterance :utterance
                confidence :confidence}
               (car (sort-hypotheses hypotheses))]
           utterance)))
    
    (def ^:dynamic *google-url*
      "https://www.google.com/speech-api/v1/recognize?xjerr=1&client=chromium&lang=en-US")
    
    (def post-to-google
      (λ [flac]
         (:body
          (clj-http.client/post
           *google-url*
           {:multipart [["Content" flac]]
            :headers {"Content-type"
                      (format "audio/x-flac; rate=%s" *sample-rate*)}}))))
    
    (def listen
      (λ []
         (let [mixer-info (clojure.core/get (AudioSystem/getMixerInfo) *input-index*)
               target (AudioSystem/getTargetDataLine *format* mixer-info)]
           ;; `with-open'?
           (.open target *format*)
           (println "I'm listening.")
           (.start target)
           (let [timer (new Timer)
                 task (proxy [TimerTask] []
                        (run []
                          (.flush target)
                          (.stop target)
                          (.close target)
                          (println "I'm considering.")
                          (.cancel timer)))]
             (.schedule timer task 10000))
           (let [input-stream (new AudioInputStream target)]
             (let [wave (create-temporary-wave)
                   flac (create-temporary-flac)]
               (AudioSystem/write input-stream
                                  AudioFileFormat$Type/WAVE
                                  wave)
               (let [encoder (new FLAC_FileEncoder)]
                 (.setStreamConfig encoder
                                   (new StreamConfiguration
                                        *channels*
                                        StreamConfiguration/DEFAULT_MIN_BLOCK_SIZE
                                        StreamConfiguration/DEFAULT_MAX_BLOCK_SIZE
                                        *sample-rate*
                                        *sample-size*))
                 (.encode encoder wave flac)
                 (parse-response (post-to-google flac))))))))
    
    (sun.misc.Signal/handle
     (sun.misc.Signal. "HUP")
     (proxy [sun.misc.SignalHandler] []
       (handle [signal]
         (answer (consider (listen))))))
    
    (loop []
      (answer (consider (listen)))
      (read-line)
      (recur))
    
  #+END_SRC
* TODO Catch signal
  #+BEGIN_SRC clojure :tangle signal.clj :shebang #!/usr/bin/env clj
    (sun.misc.Signal/handle
     (sun.misc.Signal. "HUP")
     (proxy [sun.misc.SignalHandler] []
       (handle [signal]
         (println (str "-- caught signal " signal)))))
    
    (read-line)
  #+END_SRC
* TODO Ideas
  crosswalk -> yelp -> rating (thanks, Aaron); also: we can [[http://developer.factual.com/display/docs/Core+API+-+Row+Filters][or]] things
  together.
* TODO Need a newline-newline hack (record in a thread?)
  #+BEGIN_SRC clojure :tangle threads.clj :shebang #!/usr/bin/env clj
    (use 'add-classpath.core)
    (add-classpath "lib/*")
    (add-classpath "lib/dev/*")
    
    (use 'lambda.core)
    (use 'debug.core)
    (use 'clojure.java.io)
    
    (import '(java.util Random
                        Timer
                        TimerTask))
    (import '(java.io File
                      FileOutputStream))
    
    (import '(javax.sound.sampled AudioFormat
                                  AudioSystem
                                  AudioInputStream
                                  AudioFileFormat
                                  AudioFileFormat$Type))
    
    ;; (.start (Thread. (λ [] (Thread/sleep 1000) (println "harro freunds!"))))
    
    (def format
      (new AudioFormat
           8000
           16
           1
           true
           false))
    
    (let [mixer-info (clojure.core/get (AudioSystem/getMixerInfo) 1)
          target (AudioSystem/getTargetDataLine format mixer-info)]
      ;; `with-open'?
      (.open target format)
      (println "I'm listening.")
      (.start target)
      (let [timer (new Timer)
            task (proxy [TimerTask] []
                   (run []
                     (.flush target)
                     (.stop target)
                     (.close target)
                     (println "I'm considering.")
                     (.cancel timer)))]
        (.schedule timer task 1000))
      (let [input-stream (new AudioInputStream target)]
        (let [wave (file "harro.wav")]
          (AudioSystem/write input-stream
                             AudioFileFormat$Type/WAVE
                             wave))))
    
  #+END_SRC
